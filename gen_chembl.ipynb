{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc676c00",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import rdBase\n",
    "from rdkit import RDLogger\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem import Descriptors, Draw, PandasTools, MACCSkeys, AllChem\n",
    "from rdkit.Chem.FilterCatalog import FilterCatalog, FilterCatalogParams\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "rdBase.DisableLog('rdApp.warning')\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "from unipressed import IdMappingClient\n",
    "\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b655efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_chembl_id(uniprot_id):\n",
    "    targets_api = new_client.target\n",
    "    targets = targets_api.get(target_components__accession=uniprot_id).only(\"target_chembl_id\")\n",
    "    target = targets[0]\n",
    "    chembl_id = target[\"target_chembl_id\"]\n",
    "    print(f\"ChEMBL ID: {chembl_id}\")\n",
    "    return chembl_id\n",
    "\n",
    "def get_bioactivities(chembl_id,Y):\n",
    "    bioactivities_api = new_client.activity\n",
    "    bioactivities = bioactivities_api.filter(\n",
    "        target_chembl_id=chembl_id, standard_type=Y).only(\n",
    "        \"molecule_chembl_id\",\"standard_units\",\"standard_value\",\n",
    "        \"relation\",\"activity_comment\",) # data_validity_description\n",
    "    print(f\"Fetching bioactivities for {chembl_id} ...\")\n",
    "    df = pd.DataFrame.from_dict(tqdm(bioactivities))\n",
    "    df.drop([\"units\",\"value\"], axis=1, inplace=True)\n",
    "    df = df.astype({\"standard_value\": \"float64\"})\n",
    "    df = df.rename({\"standard_value\": Y, \"standard_units\": \"units\"}, axis=\"columns\")\n",
    "    # df[\"data_validity_description\"] = df[\"data_validity_description\"].fillna(\"No comment\")\n",
    "    display(df)\n",
    "    print(f\"Initial dataset size: {df.shape[0]}\")\n",
    "    print(\"Infer relation based on activity comments\")\n",
    "    df.loc[df.activity_comment.str.contains(\"inhibition < 50% @ 10 uM\",na=False), \n",
    "           ['relation',Y,'units']] = ('>',10000,'nM')\n",
    "    print(\"Set activity comment for missing values based on relation\")\n",
    "    df.loc[(df['activity_comment'].isna()) & (df['relation'] == '=') , \n",
    "           'activity_comment'] = 'active'\n",
    "    df.loc[(df['activity_comment'].isna()) & (df['relation'] == '>') , \n",
    "           'activity_comment'] = 'inactive'\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Size after dropping NaN values: {df.shape[0]}\")\n",
    "    df = df[df[\"units\"] == \"nM\"]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Size after dropping non-standard (nM) units: {df.shape[0]}\")\n",
    "    df = df[df[Y] > 0]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Size after dropping non-positive values: {df.shape[0]}\")\n",
    "    df[\"p\"+Y] = df[Y].apply(lambda x: 9-np.log10(x))\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df['active'] = df['relation'].apply(lambda x: 1 if x == '=' else 0)\n",
    "    # df.drop_duplicates(\"molecule_chembl_id\", keep=\"first\", inplace=True)\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Size after dropping duplicate molecules: {df.shape[0]}\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def get_compounds(bioactivities_df):\n",
    "    compounds_api = new_client.molecule\n",
    "    compounds_provider = compounds_api.filter(\n",
    "        molecule_chembl_id__in=list(bioactivities_df[\"molecule_chembl_id\"])\n",
    "    ).only(\"molecule_chembl_id\",\"molecule_structures\",\"molecule_properties\")\n",
    "    print(f\"Fetching compounds ...\")\n",
    "    df = pd.DataFrame.from_records(list(tqdm(compounds_provider)))\n",
    "    display(df)\n",
    "    # Extract smiles strings\n",
    "    df['smiles'] = df.loc[\n",
    "        df['molecule_structures'].notnull(),\n",
    "        'molecule_structures'].apply(lambda x: x['canonical_smiles'])\n",
    "    df.drop(\"molecule_structures\", axis=1, inplace=True)\n",
    "    print(f\"Dataset size after filtering NaN molecules: {df.shape[0]}\")\n",
    "    # Extract Ro5 violations data\n",
    "    df['ro5_violations'] = df.loc[\n",
    "        df['molecule_properties'].notnull(),\n",
    "        'molecule_properties'].apply(lambda x: x['num_ro5_violations'])\n",
    "    df['ro5_violations'] = df['ro5_violations'].fillna(0)\n",
    "    df.drop(\"molecule_properties\", axis=1, inplace=True)\n",
    "    print(f\"Initial dataset size: {df.shape[0]}\")\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Dataset size after filtering NaN values: {df.shape[0]}\")\n",
    "    df.drop_duplicates(\"molecule_chembl_id\", keep=\"first\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Dataset size after dropping duplicates: {df.shape[0]}\")\n",
    "    df = filter(df)\n",
    "    # Must repeat the process with salt-separated SMILES\n",
    "    PandasTools.AddMoleculeColumnToFrame(df, \"smiles\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def filter(df):\n",
    "    PandasTools.AddMoleculeColumnToFrame(df, \"smiles\")\n",
    "    params = FilterCatalogParams()\n",
    "    params.AddCatalog(FilterCatalogParams.FilterCatalogs.PAINS)\n",
    "    catalog = FilterCatalog(params)\n",
    "    remover = SaltRemover()\n",
    "    df[\"smiles\"] = df[\"ROMol\"].apply(lambda x: Chem.MolToSmiles(remover.StripMol(x)))\n",
    "    df = df[~df[\"smiles\"].apply(lambda x: '.' in x)]\n",
    "    print(f\"Size after dropping multi-fragment molecules: {df.shape[0]}\")\n",
    "    # print(f\"Filtering compounds by PAINS matches ...\")\n",
    "    # df = df[~df[\"ROMol\"].progress_apply(catalog.HasMatch)]\n",
    "    # print(f\"Size after dropping PAINS hits: {df.shape[0]}\")\n",
    "    df = df.drop(\"ROMol\", axis=1)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_2D_descriptors(mol):\n",
    "    \"\"\"\n",
    "    Calculate the full set of 2D RDKit descriptors for a molecule\n",
    "    missingVal is used if the descriptor cannot be calculated\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for nm, fn in Descriptors._descList:\n",
    "        try: val = fn(mol)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            val = None\n",
    "        val = fn(mol)\n",
    "        res[nm] = val\n",
    "    return res\n",
    "\n",
    "def get_MACCS(mol):\n",
    "    \"\"\"\n",
    "    Calculate MACCS keys (166-bit)\n",
    "    \"\"\"\n",
    "    maccs = {f\"maccs_{i}\": xi for i, xi in enumerate(MACCSkeys.GenMACCSKeys(mol))}\n",
    "    return maccs\n",
    "\n",
    "def get_Morgan2(mol):\n",
    "    \"\"\"\n",
    "    Calculate radius-2 Morgan fingerprints\n",
    "    \"\"\"\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=1024)\n",
    "    morgan2 = {f\"morgan2_{i}\": xi for i, xi in enumerate(fpgen.GetFingerprint(mol))}\n",
    "    return morgan2\n",
    "\n",
    "def get_Morgan3(mol):\n",
    "    \"\"\"\n",
    "    Calculate radius-3 Morgan fingerprints\n",
    "    \"\"\"\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=3,fpSize=2048)\n",
    "    morgan3 = {f\"morgan3_{i}\": xi for i, xi in enumerate(fpgen.GetFingerprint(mol))}\n",
    "    return morgan3\n",
    "\n",
    "def get_rdkitfp(mol):\n",
    "    \"\"\"\n",
    "    Calculate RDKit fingerprints\n",
    "    \"\"\"\n",
    "    fpgen = rdFingerprintGenerator.GetRDKitFPGenerator(fpSize=1024)\n",
    "    rdkitfp = {f\"rdkitfp_{i}\": xi for i, xi in enumerate(fpgen.GetFingerprint(mol))}\n",
    "    return rdkitfp\n",
    "\n",
    "def api_calls(uniprot_id, output_csv, Y):\n",
    "    \"\"\"\n",
    "    Acquire data from ChEMBL using the\n",
    "    UniProt ID of a specific assay target\n",
    "    \"\"\"\n",
    "    tqdm.pandas()\n",
    "    print(f\"UniProt ID: {uniprot_id}\")\n",
    "    chembl_id = get_chembl_id(uniprot_id)\n",
    "    bioactivities_df = get_bioactivities(chembl_id,Y)\n",
    "    compounds_df = get_compounds(bioactivities_df)\n",
    "    df = pd.merge(\n",
    "        compounds_df[[\"molecule_chembl_id\",\"smiles\",\"ro5_violations\",\"ROMol\"]], #qed_weighted\n",
    "        bioactivities_df[[\"molecule_chembl_id\",\"relation\",Y,\"units\",\n",
    "                          \"activity_comment\",\"p\"+Y,\"active\"]], #data_validity_description\n",
    "        on=\"molecule_chembl_id\",\n",
    "    )\n",
    "    # Drop duplicates by taking the maximum reported values\n",
    "    maxima = []\n",
    "    _, idx = np.unique(df['molecule_chembl_id'].values, return_index=True)\n",
    "    smiles = df['smiles'].values[np.sort(idx)]\n",
    "    for smi in tqdm(smiles[:]):\n",
    "        mol_df = df[df['smiles'] == smi]\n",
    "        # If \"=\" equalities are available, ignore ineqaulities\n",
    "        if mol_df['relation'].str.contains('=').any(): \n",
    "            mol_df = mol_df[mol_df['relation'] == '=']\n",
    "            id = mol_df.index[np.argmax(mol_df[\"p\"+Y].values)]\n",
    "        # If only \">\" inequalities, take lowest pY (highest Y) value\n",
    "        else: id = mol_df.index[np.argmin(mol_df[\"p\"+Y].values)]\n",
    "        maxima.append(id)\n",
    "    df = df.iloc[maxima]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Size after dropping duplicate molecules: {df.shape[0]}\")\n",
    "    display(df)\n",
    "    print(f\"Shape before adding descriptors: {df.shape}\")\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Computing 2D RDKit descriptors ...\")\n",
    "    rdkit2d = pd.DataFrame([get_2D_descriptors(m) for m in tqdm(df[\"ROMol\"])])\n",
    "    df = df.join(rdkit2d)\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"Shape after adding 2D descriptors: {df.shape}\")\n",
    "    print(f\"Computing MACCS keys ...\")\n",
    "    maccs = pd.DataFrame([get_MACCS(m) for m in tqdm(df[\"ROMol\"])])\n",
    "    df = df.join(maccs)\n",
    "    print(f\"Computing radius-3 Morgan fingerprints ...\")\n",
    "    morgan3 = pd.DataFrame([get_Morgan3(m) for m in tqdm(df[\"ROMol\"])])\n",
    "    df = df.join(morgan3)\n",
    "    print(f\"Shape after adding FP descriptors: {df.shape}\")\n",
    "    print(f\"Saving data to {output_csv}\")\n",
    "    df = df.drop(\"ROMol\", axis=1)\n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv(output_csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Y = \"Ki\"\n",
    "    target = \"EGFR\"\n",
    "    request = IdMappingClient.submit(source=\"GeneCards\",dest=\"UniProtKB\",ids={target})\n",
    "    time.sleep(2.0)\n",
    "    uniprot_id = list(request.each_result())[0][\"to\"]\n",
    "    output_csv = os.path.join(target,f\"{target}_data_p{Y}.csv\")\n",
    "    api_calls(uniprot_id, output_csv, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
