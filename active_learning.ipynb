{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c858ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, ExpSineSquared, Matern, WhiteKernel\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.stats import pearsonr, mode, rankdata, percentileofscore, zscore, gaussian_kde\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from rdkit.DataStructs import ExplicitBitVect\n",
    "from rdkit.DataManip.Metric import GetTanimotoDistMat\n",
    "from rdkit.Chem import AllChem, Draw, rdFMCS\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles, MolFromSmarts, MolToSmarts\n",
    "from rdkit.Chem.MolStandardize.rdMolStandardize import Cleanup\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem.Descriptors import _descList\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTHONWARNINGS']='ignore'\n",
    "\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e3e0f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(model,Xtrain,Ytrain,parameter_ranges):\n",
    "    \"\"\"\n",
    "    Fit SK-Learn model by 5-fold cross validation hyperparameter tuning\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        parameter_ranges,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=5,\n",
    "        refit=True,\n",
    "        n_jobs=5, #-1\n",
    "        verbose=0\n",
    "    )\n",
    "    grid_search.fit(Xtrain, Ytrain)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def inference(model,X,sd=False):\n",
    "    \"\"\"\n",
    "    Return Ypred, Upred if Upred is avalilable, else return Ypred, 0\n",
    "    Ypred :: model predictions on X\n",
    "    Upred :: model uncertainty (standard deviation) on X\n",
    "    \"\"\"\n",
    "    if sd and \"return_std\" in inspect.getfullargspec(model.predict)[0]:\n",
    "        Ypred, Upred =  model.predict(X,return_std=True)\n",
    "    else: Ypred, Upred = model.predict(X), np.zeros_like(X)\n",
    "    Ypred = Ypred.reshape(-1,1)\n",
    "    Upred = Upred.reshape(-1,1)\n",
    "    return Ypred, Upred\n",
    "\n",
    "def fit_predict(model,parameter_ranges,Xtrain,Ytrain,Xtest,sd=False):\n",
    "    \"\"\"\n",
    "    Fit model to data (with Ytrain scaled to mean 0 and variance 1)\n",
    "    Run inferences of trained model on test data Xtest\n",
    "    Return Ypred, Upred if Upred is avalilable, else return Ypred, 0\n",
    "    Ypred :: model predictions on Xtest\n",
    "    Upred :: model uncertainty (standard deviation) on Xtest\n",
    "    \"\"\"\n",
    "    Ytrain = StandardScaler().fit_transform(Ytrain)\n",
    "    trained_model = fit_model(model,Xtrain,Ytrain,parameter_ranges)\n",
    "    if sd and \"return_std\" in inspect.getfullargspec(model.predict)[0]:\n",
    "        Ypred, Upred =  trained_model.predict(Xtest,return_std=True)\n",
    "    else: Ypred, Upred = trained_model.predict(Xtest), np.zeros_like(Xtest)\n",
    "    Ypred = Ypred.reshape(-1,1)\n",
    "    Upred = Upred.reshape(-1,1)\n",
    "    return trained_model, Ypred, Upred\n",
    "\n",
    "def maximise(Ypred,Upred,Ytrain,test_idx):\n",
    "    \"\"\"\n",
    "    Predicted mean acquisiton function\n",
    "    a(x) = mu(X)\n",
    "    return idx that maximises a(x)\n",
    "    \"\"\"\n",
    "    a = Ypred\n",
    "    idx = np.argmax(a)\n",
    "    best_idx = test_idx[idx]\n",
    "    return idx\n",
    "\n",
    "def UCB(Ypred,Upred,Ytrain,test_idx,l=1):\n",
    "    \"\"\"\n",
    "    Upper confidence bound acquisition function\n",
    "    a(x) = mu + lambda * sigma(x)\n",
    "    return idx that maximises a(x)\n",
    "    \"\"\"\n",
    "    a = Ypred + l * Upred\n",
    "    idx = np.argmax(a)\n",
    "    best_idx = test_idx[idx]\n",
    "    return idx\n",
    "\n",
    "def PI(Ypred,Upred,Ytrain,test_idx):\n",
    "    \"\"\"\n",
    "    Predicted Improvement acquisition function\n",
    "    a(x) = max[f(x) - f(x*)]\n",
    "    return idx that maximises a(x)\n",
    "    \"\"\"\n",
    "    Ytrain = StandardScaler().fit_transform(Ytrain.reshape(-1,1))\n",
    "    Ybest = np.max(Ytrain)\n",
    "    a = sp.stats.norm.cdf((Ypred - Ybest) / Upred)\n",
    "    idx = np.argmax(a)\n",
    "    best_idx = test_idx[idx]\n",
    "    return idx\n",
    "\n",
    "def EI(Ypred,Upred,Ytrain,test_idx):\n",
    "    \"\"\"\n",
    "    Expected Improvement acquisition function\n",
    "    a(x) = <max[f(x) - f(x*)]>\n",
    "    return idx that maximises a(x)\n",
    "    \"\"\"\n",
    "    Ytrain = StandardScaler().fit_transform(Ytrain.reshape(-1,1))\n",
    "    Ybest = np.max(Ytrain)\n",
    "    a = (Ypred - Ybest) * sp.stats.norm.cdf((Ypred - Ybest) / Upred) + \\\n",
    "       Upred * sp.stats.norm.pdf((Ypred - Ybest) / Upred)\n",
    "    idx = np.argmax(a)\n",
    "    best_idx = test_idx[idx]\n",
    "    return idx\n",
    "\n",
    "def random_sampling(Ytrain,Xtrain,Xtest,test_idx):\n",
    "    \"\"\"\n",
    "    Random acquisition function\n",
    "    return idx selected by uniform random sampling\n",
    "    \"\"\"\n",
    "    return np.random.choice(len(test_idx))\n",
    "\n",
    "def tanimoto(Ytrain,Xtrain,Xtest,test_idx):\n",
    "    \"\"\"\n",
    "    Similarity based acquisition function\n",
    "    return idx of nearest neighbour to Xbest\n",
    "    using Tanimoto (Jaccard) similarity (must use with binary features only)\n",
    "    \"\"\"\n",
    "    Xbest = Xtrain[np.argmax(Ytrain)]\n",
    "    distances = cdist([Xbest],Xtest,\"jaccard\")\n",
    "    idx = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "def cycle_limit(cycle,cycles,Ytrain,target):\n",
    "    \"\"\"\n",
    "    Stop active learning after hitting a cycle limit\n",
    "    \"\"\"\n",
    "    if cycle >= cycles: return False\n",
    "    else: return True\n",
    "\n",
    "def target_limit(cycle,cycles,Ytrain,target):\n",
    "    \"\"\"\n",
    "    Stop active learning after reaching a target threshold\n",
    "    \"\"\"\n",
    "    if np.max(Ytrain) >= target: return False\n",
    "    else: return True\n",
    "\n",
    "def preprocess(data,descriptors,train_idx,test_idx,scaler=StandardScaler(),pca=False):\n",
    "    \"\"\"\n",
    "    Preprocessing training and testing data without data leakage\n",
    "    data :: dataframe containing training and testing features\n",
    "    descriptors :: list of features corresponding to columns in data\n",
    "    train_idx :: dataframe row indices for training examples\n",
    "    test_idx :: dataframe row indices for testing examples\n",
    "    \"\"\"\n",
    "    Xtrain = data[descriptors].loc[train_idx]\n",
    "    Xtest = data[descriptors].loc[test_idx]\n",
    "    zero_columns = Xtrain.columns[(Xtrain == 0).all()].values.tolist()\n",
    "    Xtrain.drop(zero_columns,axis=1,inplace=True)\n",
    "    Xtest.drop(zero_columns,axis=1,inplace=True)\n",
    "    descriptors = Xtrain.columns\n",
    "    fp = [desc for desc in descriptors if data[desc].isin([0,1]).all()]\n",
    "    non_fp = [desc for desc in descriptors if desc not in fp]\n",
    "    corr_matrix = Xtrain[non_fp].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    Xtrain.drop(to_drop,axis=1,inplace=True)\n",
    "    Xtest.drop(to_drop,axis=1,inplace=True)\n",
    "    descriptors = Xtrain.columns\n",
    "    for desc in non_fp:\n",
    "        s = scaler\n",
    "        Xtrain[desc] = s.fit_transform(Xtrain[desc].values.reshape(-1,1))\n",
    "        Xtest[desc] = s.transform(Xtest[desc].values.reshape(-1,1))\n",
    "    if pca:\n",
    "        pca = PCA(n_components=0.95)\n",
    "        PCAtrain = pd.DataFrame(pca.fit_transform(Xtrain[non_fp]))\n",
    "        PCAtest = pd.DataFrame(pca.transform(Xtest[non_fp]))\n",
    "        PCAtrain[fp] = Xtrain[fp]\n",
    "        PCAtest[fp] = Xtest[fp]\n",
    "        Xtrain = PCAtrain\n",
    "        Xtest = PCAtest\n",
    "    return Xtrain.values.tolist(), Xtest.values.tolist()\n",
    "\n",
    "\n",
    "def active_learning(data,descriptors,label,\n",
    "                    oracle_fn,acquisition_fn,termination_fn,\n",
    "                    n,N,target,\n",
    "                    model_class,parameter_ranges,\n",
    "                    initial=\"random\",lowlevel=\"\",\n",
    "                    predict=True,sd=False):\n",
    "    \"\"\"\n",
    "    Main active learning loop\n",
    "    data :: Pandas Dataframe object\n",
    "    descriptors :: List of strings specifying descriptors (X value) column name\n",
    "    label :: List of a string specifying label (Y value) column name\n",
    "    oracle_fn :: Function for parsing the label (Y) for a given data point (idx)\n",
    "    acquisition_fn :: Function for selecting a given data point (idx) from a pool\n",
    "    termination_fn :: Function for determining when to stop active learning cycle\n",
    "    n :: Number of training data points in initial pool\n",
    "    N :: Maximum number of active learning loops\n",
    "    target :: Label value target threshold\n",
    "    model_class :: Machine Learning model\n",
    "    parameter_ranges :: Hyperparameter ranges for tuning\n",
    "    initial :: Method for choosing initial pool\n",
    "    lowlevel :: Feature acting as a low-level predictor of the target\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial sample\n",
    "    test_idx = list(data.index.values)\n",
    "    size = len(test_idx)\n",
    "    if size <= n:\n",
    "        # Do not attempt AL for datasets smaller than n\n",
    "        sample_size = size\n",
    "        cycles = 0\n",
    "        train_idx = test_idx\n",
    "        active = False\n",
    "    elif size > n:\n",
    "        # Random initial sample for first AL cycle\n",
    "        sample_size = n\n",
    "        cycles = min(N,size-n)\n",
    "        if initial==\"random\":\n",
    "            # Initial pool of size n selected at random\n",
    "            rand_idx = np.random.choice(size,n,replace=False)\n",
    "            train_idx = np.array(test_idx)[rand_idx].tolist()\n",
    "        elif initial==\"top\":\n",
    "            # Initial pool of size n selected by low-level feature\n",
    "            vals = mol_data[lowlevel].values\n",
    "            # train_idx = np.argsort(vals)[::-1][:n].tolist() # (top-n)\n",
    "            P = np.where(vals >= np.percentile(vals,90))[0] # (P90)\n",
    "            train_idx = np.random.choice(P,n,replace=False).tolist() # (P90)\n",
    "        elif initial==\"cpca\":\n",
    "            # Initial pool of size n selected at random from n-means pca-2 clusters\n",
    "            cluster = f\"cpca_{n}\"\n",
    "            train_idx = []\n",
    "            for i in range(n):\n",
    "                cluster_idx = data.index[data[cluster]==i]\n",
    "                if len(cluster_idx) > 0: train_idx.append(np.random.choice(cluster_idx))\n",
    "        elif initial==\"ctsne\":\n",
    "            # Initial pool of size n selected at random from n-means tsne-95 clusters\n",
    "            cluster = f\"ctsne_{n}\"\n",
    "            train_idx = []\n",
    "            for i in range(n):\n",
    "                cluster_idx = data.index[data[cluster]==i]\n",
    "                if len(cluster_idx) > 0: train_idx.append(np.random.choice(cluster_idx))\n",
    "        elif initial==\"dockdiv\":\n",
    "            # Initial pool of size n selected at random from n-means pca-2 clusters of top 50%\n",
    "            cluster = f\"dcpca_{n}\"\n",
    "            train_idx = []\n",
    "            for i in range(n):\n",
    "                cluster_idx = data.index[data[cluster]==i]\n",
    "                if len(cluster_idx) > 0: train_idx.append(np.random.choice(cluster_idx))\n",
    "        elif initial==\"divdock\":\n",
    "            # Initial pool of size n selected at random from top 50% of n-means pca-2 clusters\n",
    "            cluster = f\"cpca_{n}\"\n",
    "            train_idx = []\n",
    "            for i in range(n):\n",
    "                cluster_idx = data.index[data[cluster]==i]\n",
    "                if len(cluster_idx) > 0:\n",
    "                    vals = mol_data[lowlevel].iloc[cluster_idx].values\n",
    "                    P = cluster_idx[np.where(vals >= np.percentile(vals,90))[0]] # 50\n",
    "                    train_idx.append(np.random.choice(P))\n",
    "        test_idx = np.delete(test_idx,train_idx).tolist()\n",
    "        Xtrain = data[descriptors].loc[train_idx].values.tolist()\n",
    "        Xtest = data[descriptors].loc[test_idx].values.tolist()\n",
    "        # Xtrain, Xtest = preprocess(data,descriptors,train_idx,test_idx)\n",
    "        active = True\n",
    "\n",
    "    # Query oracle for training data\n",
    "    Ytrain = [oracle_fn(idx) for idx in train_idx]\n",
    "\n",
    "\n",
    "    # Begin active learning loop\n",
    "    cycle = 0\n",
    "    while active:\n",
    "        cycle += 1\n",
    "\n",
    "        # Select data point\n",
    "        # trained_model = fit_model(model,Xtrain,Ytrain,parameter_ranges)\n",
    "        # Ypred, Upred = inference(trained_model,Xtest,sd)\n",
    "        if predict:\n",
    "            model = model_class\n",
    "            trained_model, Ypred, Upred = fit_predict(model,parameter_ranges,Xtrain,Ytrain,Xtest,sd)\n",
    "            idx = acquisition_fn(Ypred,Upred,Ytrain,test_idx)\n",
    "        elif not predict:\n",
    "            if acquisition_fn in [random_sampling, tanimoto]:\n",
    "                new_fn = acquisition_fn\n",
    "            else: new_fn = random_sampling\n",
    "            # Random or similarity-based search\n",
    "            idx = new_fn(Ytrain,Xtrain,Xtest,test_idx)\n",
    "\n",
    "        train_idx.append(test_idx.pop(idx))\n",
    "        Xtrain.append(Xtest.pop(idx))\n",
    "\n",
    "        # Query oracle for selected data point\n",
    "        Ytrain_new = oracle_fn(train_idx[-1])\n",
    "        Ytrain.append(Ytrain_new)\n",
    "\n",
    "        # Test for termination conditions\n",
    "        active = termination_fn(cycle,cycles,Ytrain,target)\n",
    "        if len(test_idx) == 0: active = False\n",
    "\n",
    "    # oracle_calls = sample_size + cycle\n",
    "    if predict: idx = acquisition_fn(Ytrain,np.zeros_like(Ytrain),Ytrain,train_idx)\n",
    "    elif not predict: idx = acquisition_fn(Ytrain,Xtrain,Xtrain,train_idx)\n",
    "    best_idx = train_idx[idx]\n",
    "    best_Y = Ytrain[idx]\n",
    "\n",
    "    return train_idx, Ytrain, best_idx, best_Y\n",
    "\n",
    "def random_analytic(D,v):\n",
    "    \"\"\"\n",
    "    Analytic form of random sampling without replacement\n",
    "    derived from the negative hypergeometic distribution\n",
    "    D :: Data (list or 1D array of numerics)\n",
    "    N :: Total finite population size\n",
    "    v :: Hit target value\n",
    "    H :: Number of 'hits'\n",
    "    returns :: Expected number of random samples\n",
    "    required to reach at least one 'hit'\n",
    "    \"\"\"\n",
    "    N = len(D)\n",
    "    quantile = (D < v).sum() / N\n",
    "    H = int(round((1 - quantile) * N))\n",
    "    return (N + 1) / (H + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bcafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model constants\n",
    "models = [\n",
    "\tLinearRegression(),\n",
    "\tRidge(random_state=rng),\n",
    "        BayesianRidge(),\n",
    "        LinearSVR(random_state=rng),\n",
    "        SVR(),\n",
    "\tRandomForestRegressor(random_state=rng),\n",
    "\tKernelRidge(),\n",
    "\tGaussianProcessRegressor(random_state=rng),\n",
    "\tXGBRegressor(random_state=rng)\n",
    "]\n",
    "model_names = [\n",
    "    \"LR\",\"RR\",\"BRR\",\"lSVR\",\"SVR\",\"RFR\",\"KRR\",\"GPR\",\"XGB\"\n",
    "]\n",
    "RBF_kernel = RBF()\n",
    "RQ_kernel = RationalQuadratic()\n",
    "Matern_kernel = Matern()\n",
    "ESS_kernel = ExpSineSquared()\n",
    "White_kernel = WhiteKernel()\n",
    "parameter_ranges = [\n",
    "    {\"fit_intercept\": [True, False]},\n",
    "    {\"alpha\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100]},\n",
    "    {\"alpha_1\":[1e-6],\n",
    "     \"alpha_2\":[1e-6],\n",
    "     \"lambda_1\":[1e-6],\n",
    "     \"lambda_2\":[1e-6]\n",
    "    },\n",
    "    {\"C\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100]},\n",
    "    {\"C\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100],\n",
    "     \"kernel\": [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "     \"degree\": [1,2,3],\n",
    "     \"epsilon\": [1.0,0.1,0.001,0.0001],\n",
    "    },\n",
    "    {\"n_estimators\": [50, 100, 200],\n",
    "     \"max_depth\": [5, 10, 50, 100]\n",
    "    },\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"alpha\": [1e-3,1e-2,1e-1,1],\n",
    "     \"gamma\": [1e-3,1e-2,1e-1,1],\n",
    "     \"degree\": [2, 3, 4]\n",
    "    },\n",
    "    {\"kernel\": [\n",
    "\t1.0 * RBF_kernel,\n",
    "        1.0 * RQ_kernel,\n",
    "        1.0 * Matern_kernel,\n",
    "\t1.0 * RQ_kernel + 1.0 * Matern_kernel,\n",
    "        ],\n",
    "    },\n",
    "    {\"n_estimators\": [50, 100, 200],\n",
    "     \"max_depth\": [5, 10, 50, 100],\n",
    "     \"eta\": [0.1, 0.01, 0.001],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "good_rdkit3d = [\"PMI1\", \"PMI2\", \"RadiusOfGyration\", \"PBF\"]\n",
    "good_rdkit2d = ['MaxEStateIndex','MinEStateIndex','qed','MolWt','MaxPartialCharge','MinPartialCharge',\n",
    "    'FpDensityMorgan3','BCUT2D_CHGHI','BCUT2D_CHGLO','BCUT2D_LOGPHI','BCUT2D_LOGPLOW','BalabanJ',\n",
    "    'BertzCT','Chi0n','Chi0v','Chi1n','Chi1v','Chi2n','Chi2v','Chi3n','Chi3v','Chi4n','Chi4v',\n",
    "    'HallKierAlpha','Ipc','Kappa1','Kappa2','Kappa3','LabuteASA',\n",
    "    'SlogP_VSA1','SlogP_VSA10','SlogP_VSA11','SlogP_VSA12','SlogP_VSA2','SlogP_VSA3','SlogP_VSA4',\n",
    "    'SlogP_VSA5','SlogP_VSA6','SlogP_VSA7','SlogP_VSA8','SlogP_VSA9',\n",
    "    'TPSA','FractionCSP3','NHOHCount','NOCount','NumAliphaticCarbocycles','NumAliphaticHeterocycles',\n",
    "    'NumAliphaticRings','NumAromaticCarbocycles','NumAromaticHeterocycles','NumAromaticRings',\n",
    "    'NumHAcceptors','NumHDonors','NumHeteroatoms','NumRotatableBonds','NumSaturatedCarbocycles',\n",
    "    'NumSaturatedHeterocycles','NumSaturatedRings','RingCount','MolLogP','MolMR',\n",
    "    'fr_benzene','fr_phenol','fr_aniline','fr_ArN','fr_pyridine','fr_Nhpyrrole','fr_bicyclic',\n",
    "    'fr_NH0','fr_C_O','fr_halogen']\n",
    "\n",
    "\n",
    "# Descriptor constants\n",
    "descriptors = {\n",
    "    #\"rdkit2d\":[desc[0] for desc in set(_descList)],\n",
    "    \"rdkit2d\":good_rdkit2d,\n",
    "    \"maccs\":[f\"maccs_{i}\" for i in range(167)],\n",
    "    \"morgan3\":[f\"morgan3_{i}\" for i in range(2048)], #2048\n",
    "    #\"rdkit3d\":['PMI1','PMI2','PMI3','NPR1', 'NPR2', 'RadiusOfGyration',\n",
    "    #    'InertialShapeFactor','Eccentricity','Asphericity','SpherocityIndex','PBF'],\n",
    "    \"rdkit3d\": good_rdkit3d,\n",
    "    \"autocorr3d\":[f\"AUTOCORR3D_{i}\" for i in range(80)],\n",
    "    \"rdf\":[f\"RDF_{i}\" for i in range(210)],\n",
    "    \"getaway\":[f\"GETAWAY_{i}\" for i in range(273)],\n",
    "    \"whim\":[f\"WHIM_{i}\" for i in range(114)],\n",
    "    \"vina\":[f\"vinaF_{i}\" for i in range(49)],\n",
    "    \"sasa\":[f\"sasaF_{i}\" for i in range(30)],\n",
    "    \"lig\":[f\"ligF_{i}\" for i in range(10)],\n",
    "    \"wat\":[f\"watF_{i}\" for i in range(3)],\n",
    "    \"delta\":[\"score\",\"betaScore\",\"ligCover\",\"LinF9\"],\n",
    "    \"docking\":[\"XGB\"],\n",
    "    \"noised04\":[\"noised_04\"],\n",
    "    \"noised08\":[\"noised_08\"],\n",
    "    \"noised12\":[\"noised_12\"],\n",
    "    \"noised16\":[\"noised_16\"],\n",
    "    \"noised24\":[\"noised_24\"],\n",
    "    \"noised32\":[\"noised_32\"],\n",
    "    \"noise01\": [\"noise_01\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs =[\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\",],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"EGFR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\",],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"LCK-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"JAK2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"MAOB-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NOS1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PARP1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ACHE-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PDE5A-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"PTGS2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ESR1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"NR3C1-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\",],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"AR-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"F10-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"random\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"tanimoto\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"random\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"cpca\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"docking\",],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "    {\"dataset\":\"ADRB2-2048\",\"label\":\"pKi\",\"model\":\"BRR\",\"acquisition\":\"maximise\",\"descriptors\":[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\"m\":10,\"M\":10000,\"initial\":\"top\",\"lowlevel\":\"XGB\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for config in configs:\n",
    "\n",
    "    # Determine data, model, descriptors and active learning configuration\n",
    "    Nrep = 25\n",
    "    datafile = f\"{config['dataset']}_data_3d_delta_pKi.csv\"\n",
    "    mol_data = pd.read_csv(os.path.join(\"data\",datafile))\n",
    "    mol_label = [config[\"label\"]]\n",
    "    label_values = mol_data[mol_label].values\n",
    "    m = config[\"m\"]\n",
    "    M = config[\"M\"]\n",
    "    if \"mol_target\" in config.keys(): mol_target = config[\"mol_target\"]\n",
    "    else: mol_target = np.max(label_values)\n",
    "    def mol_oracle(mol_idx,data=mol_data,label=mol_label):\n",
    "        return data[label].iloc[mol_idx].values.tolist()\n",
    "    if \"acquisition\" in config.keys():\n",
    "        if config[\"acquisition\"] == \"maximise\":\n",
    "            acquisition = \"\"\n",
    "            mol_acquisition = maximise\n",
    "            sd = False\n",
    "            predict = True\n",
    "        elif config[\"acquisition\"] == \"UCB\":\n",
    "            acquisition = \"UCB\"\n",
    "            mol_acquisition = UCB\n",
    "            sd = True\n",
    "            predict = True\n",
    "        elif config[\"acquisition\"] == \"PI\":\n",
    "            acquisition = \"PI\"\n",
    "            mol_acquisition = PI\n",
    "            sd = True\n",
    "            predict = True\n",
    "        elif config[\"acquisition\"] == \"EI\":\n",
    "            acquisition = \"EI\"\n",
    "            mol_acquisition = EI\n",
    "            sd = True\n",
    "            predict = True\n",
    "        elif config[\"acquisition\"] == \"random\":\n",
    "            acquisition = \"random\"\n",
    "            mol_acquisition = random_sampling\n",
    "            sd = False\n",
    "            predict = False\n",
    "        elif config[\"acquisition\"] == \"tanimoto\":\n",
    "            acquisition = \"tanimoto\"\n",
    "            mol_acquisition = tanimoto\n",
    "            sd = False\n",
    "            predict = False\n",
    "    else:\n",
    "        acquisition = \"\"\n",
    "        mol_acquisition = maximise\n",
    "        sd = False\n",
    "        predict = True\n",
    "    if predict:\n",
    "        mol_model = models[model_names.index(config[\"model\"])]\n",
    "        mol_ranges = parameter_ranges[model_names.index(config[\"model\"])]\n",
    "    elif not predict:\n",
    "        config[\"model\"] = \"\"\n",
    "        mol_model = None\n",
    "        mol_ranges = None\n",
    "    if \"initial\" in config.keys(): initial = config[\"initial\"]\n",
    "    else: initial=\"random\"\n",
    "    if \"lowlevel\" in config.keys(): lowlevel = config[\"lowlevel\"]\n",
    "    else: lowlevel=\"\"\n",
    "    mol_termination = target_limit\n",
    "    if \"scaling\" in config.keys(): scaling = config[\"scaling\"]\n",
    "    else: scaling = True\n",
    "    if \"pca\" in config.keys(): pca = config[\"pca\"]\n",
    "    else: pca = False\n",
    "    mol_desc = sum([descriptors[d] for d in config[\"descriptors\"]], [])\n",
    "    job = \"\"\n",
    "    job += config[\"dataset\"]\n",
    "    if config[\"model\"] != \"\": job += \"_\"+config[\"model\"]\n",
    "    if acquisition != \"\": job += \"_\"+acquisition\n",
    "    if acquisition != \"random\":\n",
    "        for d in config[\"descriptors\"]: job += \"_\"+d\n",
    "    if pca: job += \"_pca\"\n",
    "    job += \"_\"+str(config[\"m\"])\n",
    "    if initial == \"top\" and lowlevel: job += \"_top_\"+lowlevel+\"_P90\"\n",
    "    elif initial == \"cpca\": job += \"_cpca\"\n",
    "    elif initial == \"ctsne\": job += \"_ctsne\"\n",
    "    elif initial == \"dockdiv\": job += \"_dockdiv_\"+lowlevel+\"_P90\"\n",
    "    elif initial == \"divdock\": job += \"_divdock_\"+lowlevel+\"_P90\"\n",
    "    print(f\"Running {job} ...\")\n",
    "\n",
    "    # Preprocess descriptors by removing zero-variance columns and highly correlated features\n",
    "    # also scale descriptors to zero mean and unit standard deviation, and optionally reduce dimensionality\n",
    "    zero_columns = np.where(mol_data[mol_desc].std() == 0)[0]\n",
    "    mol_desc = [desc for desc in mol_desc if desc not in zero_columns]\n",
    "    fp = [desc for desc in mol_desc if mol_data[desc].isin([0,1]).all()]\n",
    "    non_fp = [desc for desc in mol_desc if desc not in fp]\n",
    "    corr_matrix = mol_data[non_fp].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    mol_desc = [desc for desc in mol_desc if desc not in to_drop]\n",
    "    if scaling:\n",
    "        for desc in non_fp:\n",
    "            mol_data[desc] = StandardScaler().fit_transform(mol_data[desc].values.reshape(-1,1))\n",
    "    if pca:\n",
    "        pca_data = pd.DataFrame(PCA(n_components=0.95).fit_transform(mol_data[non_fp]))\n",
    "        pca_desc = [f\"PCA_{i}\" for i in range(pca_data.shape[1])]\n",
    "        pca_data.columns = pca_desc\n",
    "        pca_data[mol_label+fp] = mol_data.copy()[mol_label+fp]\n",
    "        mol_data = pca_data\n",
    "        mol_desc = pca_desc+fp\n",
    "    print(f\"Feature length: {len(mol_desc)}\")\n",
    "    # Begin active learning over Nrep (default: 25) random seeds\n",
    "    # determine number of queries required to reach a given checkpoint target\n",
    "    # always \"full pass\" so trajectories run until global maxima is located\n",
    "    targets = [7+0.1*i for i in range(int((mol_target-7)/0.1)+1)]+[mol_target]\n",
    "    #print(targets)\n",
    "    queries = []\n",
    "    ids = []\n",
    "    for i in tqdm(range(Nrep)):\n",
    "        np.random.seed(i)\n",
    "        try:\n",
    "            train_idx, Ytrain, best_pred_idx, best_Ypred = active_learning(\n",
    "                mol_data,mol_desc,mol_label,\n",
    "                mol_oracle,mol_acquisition,mol_termination,\n",
    "                m,M,mol_target,\n",
    "                mol_model,mol_ranges,\n",
    "                initial,lowlevel,\n",
    "                predict,sd)\n",
    "            checkpoints = [np.argmax(np.array(Ytrain).flatten() >= target)+1 for target in targets]\n",
    "            queries.append(checkpoints)\n",
    "            ids.append(train_idx)\n",
    "        except Exception as e: print(e) # in some cases, errors may arise from np.linalg\n",
    "\n",
    "    # Collect results as csv\n",
    "    outdir = \"results\"\n",
    "    if not os.path.exists(outdir): os.mkdir(outdir)\n",
    "    queries = np.array(queries)\n",
    "    id_df = pd.DataFrame(ids).transpose()\n",
    "    id_df.columns = [f\"run_{i}\" for i in range(len(ids))]\n",
    "    id_df.to_csv(os.path.join(outdir,f\"{job}_ID.csv\"),index=False)\n",
    "    target_data = mol_data[mol_label].values\n",
    "    target_data = mol_data[mol_label].values\n",
    "    mean_queries = np.mean(queries,axis=0)\n",
    "    std_queries = np.std(queries,axis=0)\n",
    "    max_queries = np.max(queries,axis=0)\n",
    "    min_queries = np.min(queries,axis=0)\n",
    "    rand_queries = [random_analytic(target_data,target) for target in targets]\n",
    "\n",
    "    results = {\n",
    "        \"targets\":targets,\n",
    "        \"mean_queries\":mean_queries,\n",
    "        \"std_queries\":std_queries,\n",
    "        \"max_queries\":max_queries,\n",
    "        \"min_queries\":min_queries,\n",
    "        \"rand_queries\":rand_queries,\n",
    "    }\n",
    "    results_df = pd.DataFrame.from_dict(results,orient=\"index\").transpose()\n",
    "    results_df.to_csv(os.path.join(outdir,f\"{job}.csv\"),index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
