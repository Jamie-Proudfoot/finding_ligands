{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c76bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "import inspect\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, ExpSineSquared, Matern, WhiteKernel\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import _descList\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"]=str(seed)\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49632af7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "good_rdkit3d = [\"PMI1\", \"PMI2\", \"RadiusOfGyration\", \"PBF\"]\n",
    "good_rdkit2d = ['MaxEStateIndex','MinEStateIndex','qed','MolWt','MaxPartialCharge','MinPartialCharge',\n",
    "    'FpDensityMorgan3','BCUT2D_CHGHI','BCUT2D_CHGLO','BCUT2D_LOGPHI','BCUT2D_LOGPLOW','BalabanJ',\n",
    "    'BertzCT','Chi0n','Chi0v','Chi1n','Chi1v','Chi2n','Chi2v','Chi3n','Chi3v','Chi4n','Chi4v',\n",
    "    'HallKierAlpha','Ipc','Kappa1','Kappa2','Kappa3','LabuteASA',\n",
    "    'SlogP_VSA1','SlogP_VSA10','SlogP_VSA11','SlogP_VSA12','SlogP_VSA2','SlogP_VSA3','SlogP_VSA4',\n",
    "    'SlogP_VSA5','SlogP_VSA6','SlogP_VSA7','SlogP_VSA8','SlogP_VSA9',\n",
    "    'TPSA','FractionCSP3','NHOHCount','NOCount','NumAliphaticCarbocycles','NumAliphaticHeterocycles',\n",
    "    'NumAliphaticRings','NumAromaticCarbocycles','NumAromaticHeterocycles','NumAromaticRings',\n",
    "    'NumHAcceptors','NumHDonors','NumHeteroatoms','NumRotatableBonds','NumSaturatedCarbocycles',\n",
    "    'NumSaturatedHeterocycles','NumSaturatedRings','RingCount','MolLogP','MolMR',\n",
    "    'fr_benzene','fr_phenol','fr_aniline','fr_ArN','fr_pyridine','fr_Nhpyrrole','fr_bicyclic',\n",
    "    'fr_NH0','fr_C_O','fr_halogen']\n",
    "descriptors = {\n",
    "    # \"rdkit2d\":[desc[0] for desc in set(_descList)],\n",
    "\t\"rdkit2d\":good_rdkit2d,\n",
    "    \"maccs\":[f\"maccs_{i}\" for i in range(166)],\n",
    "    \"morgan3\":[f\"morgan3_{i}\" for i in range(2048)],\n",
    "    # \"rdkit3d\":['PMI1','PMI2','PMI3','NPR1', 'NPR2', 'RadiusOfGyration',\n",
    "    #     'InertialShapeFactor','Eccentricity','Asphericity','SpherocityIndex','PBF'],\n",
    "\t\"rdkit3d\":good_rdkit3d,\n",
    "    \"autocorr3d\":[f\"AUTOCORR3D_{i}\" for i in range(80)],\n",
    "    \"rdf\":[f\"RDF_{i}\" for i in range(210)],\n",
    "    \"getaway\":[f\"GETAWAY_{i}\" for i in range(273)],\n",
    "    \"whim\":[f\"WHIM_{i}\" for i in range(114)],\n",
    "    \"vina\":[f\"vinaF_{i}\" for i in range(49)],\n",
    "    \"sasa\":[f\"sasaF_{i}\" for i in range(30)],\n",
    "    \"lig\":[f\"ligF_{i}\" for i in range(10)],\n",
    "    \"wat\":[f\"watF_{i}\" for i in range(3)],\n",
    "    \"delta\":[\"score\",\"betaScore\",\"ligCover\",\"LinF9\"],\n",
    "    \"docking\":[\"XGB\"],\n",
    "    \"noised04\":[\"noised_04\"],\n",
    "    \"noised08\":[\"noised_08\"],\n",
    "    \"noised12\":[\"noised_12\"],\n",
    "    \"noised16\":[\"noised_16\"],\n",
    "    \"noised24\":[\"noised_24\"],\n",
    "    \"noised32\":[\"noised_32\"],\n",
    "    \"noise01\": [\"noise_01\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(model, parameter_ranges, Xtrain, Ytrain):\n",
    "\tgrid_search = GridSearchCV(\n",
    "\t\tmodel, \n",
    "\t\tparameter_ranges, \n",
    "\t\tscoring=\"neg_mean_absolute_error\", \n",
    "\t\tcv=5, \n",
    "\t\trefit=True, \n",
    "\t\tn_jobs=2,\n",
    "\t\tverbose=1\n",
    "\t)\n",
    "\tgrid_search.fit(Xtrain, Ytrain)\n",
    "\tprint(grid_search.best_params_)\n",
    "\treturn grid_search.best_estimator_\n",
    "\n",
    "def fit_predict(model,parameter_ranges,Xtrain,Ytrain,Xtest,sd=False):\n",
    "    Ytrain = StandardScaler().fit_transform(Ytrain)\n",
    "    trained_model = fit_model(model,Xtrain,Ytrain,parameter_ranges)\n",
    "    if sd and \"return_std\" in inspect.getfullargspec(model.predict)[0]:\n",
    "        Ypred, Upred =  trained_model.predict(Xtest,return_std=True)\n",
    "    else: Ypred, Upred = trained_model.predict(Xtest), np.zeros_like(Xtest)\n",
    "    Ypred = Ypred.reshape(-1,1)\n",
    "    Upred = Upred.reshape(-1,1)\n",
    "    return trained_model, Ypred, Upred\n",
    "\n",
    "def make_plot(model, Ypred, Y):\n",
    "\tplt.scatter(Ypred, Y, c=\"blue\", s=2, alpha=0.5)\n",
    "\tplt.xlabel(\"Predicted\")\n",
    "\tplt.ylabel(\"True\")\n",
    "\tplt.title(f\"{str(model).split('(')[0]}() test results\")\n",
    "\t# plt.axis(\"equal\")\n",
    "\tplt.show()\n",
    "\n",
    "def evaluate_model(model, parameter_ranges, Xtrain, Ytrain, Xtest, Ytest, plot=False):\n",
    "\ttrain_scaler = StandardScaler().fit(Ytrain.reshape(-1,1))\n",
    "\ttrain_scale = train_scaler.scale_\n",
    "\tYtrain = train_scaler.transform(Ytrain.reshape(-1,1))\n",
    "\ttest_scaler = StandardScaler().fit(Ytest.reshape(-1,1))\n",
    "\ttest_scale = test_scaler.scale_\n",
    "\tYtest = test_scaler.transform(Ytest.reshape(-1,1))\n",
    "\ttrained_model = fit_model(model, parameter_ranges, Xtrain, Ytrain)\n",
    "\tYtrain_pred = trained_model.predict(Xtrain)\n",
    "\tYtest_pred = trained_model.predict(Xtest)\n",
    "\tif plot:\n",
    "\t\tmake_plot(model, Ytest_pred, Ytest)\n",
    "\t\tLearningCurveDisplay.from_estimator(trained_model, Xtrain, Ytrain, scoring=\"neg_mean_absolute_error\")\n",
    "\t\tplt.show()\n",
    "\tYtrain = Ytrain.flatten()\n",
    "\tYtrain_pred = Ytrain_pred.flatten()\n",
    "\tYtest = Ytest.flatten()\n",
    "\tYtest_pred = Ytest_pred.flatten()\n",
    "\ttrain_error = mean_absolute_error(Ytrain_pred, Ytrain) * train_scale\n",
    "\ttest_error = mean_absolute_error(Ytest_pred, Ytest) * test_scale\n",
    "\ttrain_r = pearsonr(Ytrain_pred, Ytrain).statistic\n",
    "\ttest_r = pearsonr(Ytest_pred, Ytest).statistic\n",
    "\ttrain_sr = spearmanr(Ytrain_pred, Ytrain).statistic\n",
    "\ttest_sr = spearmanr(Ytest_pred, Ytest).statistic\n",
    "\ttrain_kr = kendalltau(Ytrain_pred, Ytrain).statistic\n",
    "\ttest_kr = kendalltau(Ytest_pred, Ytest).statistic\n",
    "\tresults = (\n",
    "\t\ttrain_error, test_error, train_r, test_r, train_sr, test_sr, train_kr, test_kr,\n",
    "\t)\n",
    "\tprint(len(results))\n",
    "\treturn results\n",
    "\n",
    "def generate_datasets(data, rstate, train_size=10,\n",
    "\t\t\t\t\t  features=[\"morgan3\"], descriptors=descriptors,\n",
    "\t\t\t\t\t  scaling=True, pca=False,\n",
    "\t\t\t\t\t  target=\"pKi\",\n",
    "\t\t\t\t\t  initial=\"random\", lowlevel=\"XGB\",):\n",
    "\tmol_desc = sum([descriptors[d] for d in features], [])\n",
    "\ttarget = target\n",
    "\tprint(\"Removing zero-valued features...\")\n",
    "\tzero_columns = data[mol_desc].columns[(data[mol_desc] == 0).all()].values.tolist()\n",
    "\tprint(zero_columns)\n",
    "\tmol_desc = [desc for desc in mol_desc if desc not in zero_columns]\n",
    "\tprint(\"Removing highly correlated features...\")\n",
    "\tfp = [desc for desc in mol_desc if data[desc].isin([0,1]).all()]\n",
    "\tnon_fp = [desc for desc in mol_desc if desc not in fp]\n",
    "\tcorr_matrix = data[non_fp].corr().abs()\n",
    "\tupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\tto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\tprint(to_drop)\n",
    "\tmol_desc = [desc for desc in mol_desc if desc not in to_drop]\n",
    "\tif scaling:\n",
    "\t\tprint(\"Scaling non-fingerprint features...\")\n",
    "\t\tfor desc in non_fp: data[desc] = StandardScaler().fit_transform(data[desc].values.reshape(-1,1))\n",
    "\tif pca:\n",
    "\t\tprint(\"PCA decomposition on non-fignerprint features...\")\n",
    "\t\tpca = PCA(n_components=0.95)\n",
    "\t\tPCAset = pd.DataFrame(pca.fit_transform(data[non_fp]))\n",
    "\t\tpca_desc = [f\"PC_{i}\" for i in range(len(PCAset.columns))]\n",
    "\t\tPCAset.columns = pca_desc\n",
    "\t\tPCAset[fp+[target]] = data[fp+[target]]\n",
    "\t\tmol_desc = pca_desc + fp\n",
    "\t\tdata = PCAset\n",
    "\tX = data[mol_desc].to_numpy(dtype=float)\n",
    "\tY = data[target].to_numpy(dtype=float)\n",
    "\tXtrain, Ytrain, Xtest, Ytest = initialisation(\n",
    "\t\tdata,X,Y,train_size,initial,lowlevel,rstate)\n",
    "\treturn Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "def initialisation(data, X, Y, n, initial, lowlevel, rstate):\n",
    "\tnp.random.seed(rstate)\n",
    "\tsize = len(data.index)\n",
    "\ttest_idx = data.index\n",
    "\tif initial==\"random\":\n",
    "\t\t# Initial pool of size n selected at random\n",
    "\t\trand_idx = np.random.choice(size,n,replace=False)\n",
    "\t\ttrain_idx = np.array(test_idx)[rand_idx].tolist()\n",
    "\telif initial==\"top\":\n",
    "\t\t# Initial pool of size n selected by low-level feature\n",
    "\t\tvals = data[lowlevel].values\n",
    "\t\t# train_idx = np.argsort(vals)[::-1][:n].tolist() # (top-n)\n",
    "\t\tP = np.where(data[lowlevel].values >= np.percentile(vals,90))[0] #(P90)\n",
    "\t\ttrain_idx = np.random.choice(P,n,replace=False).tolist() #(P90)\n",
    "\telif initial==\"cpca\":\n",
    "\t\t# Initial pool of size n selected at random from n-means pca-2 clusters\n",
    "\t\tcluster = f\"cpca_{n}\"\n",
    "\t\ttrain_idx = []\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tcluster_idx = data.index[data[cluster]==i]\n",
    "\t\t\tif len(cluster_idx) > 0: train_idx.append(np.random.choice(cluster_idx))\n",
    "\telif initial==\"ctsne\":\n",
    "\t\t# Initial pool of size n selected at random from n-means tsne-95 clusters\n",
    "\t\tcluster = f\"ctsne_{n}\"\n",
    "\t\ttrain_idx = []\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tcluster_idx = data.index[data[cluster]==i]\n",
    "\t\t\tif len(cluster_idx) > 0: train_idx.append(np.random.choice(cluster_idx))\n",
    "\ttest_idx = np.delete(test_idx,train_idx)\n",
    "\tXtrain = X[train_idx]\n",
    "\tYtrain = Y[train_idx]\n",
    "\tXtest = X[test_idx]\n",
    "\tYtest = Y[test_idx]\n",
    "\treturn Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "def test_models(models, parameter_ranges, data, \n",
    "\t\t\t\tfeatures=[\"morgan3\"], target=\"pKi\",\n",
    "\t\t\t\tn_repeats=5, train_size=10, \n",
    "\t\t\t\tinitial=\"random\", lowlevel=\"XGB\",\n",
    "\t\t\t\tplot=False):\n",
    "\ttrain_scores = np.zeros(len(models))\n",
    "\ttest_scores = np.zeros(len(models))\n",
    "\ttrain_square_errors = np.zeros(len(models))\n",
    "\ttest_square_errors = np.zeros(len(models))\n",
    "\ttrain_pearsonr = np.zeros(len(models))\n",
    "\ttest_pearsonr = np.zeros(len(models))\n",
    "\ttrain_spearmanr = np.zeros(len(models))\n",
    "\ttest_spearmanr = np.zeros(len(models))\n",
    "\ttrain_kendalltau = np.zeros(len(models))\n",
    "\ttest_kendalltau = np.zeros(len(models))\n",
    "\tfor r in tqdm(range(n_repeats)):\n",
    "\t\tprint(f\"Repeat number: {r}\")\n",
    "\t\tXtrain, Ytrain, Xtest, Ytest = generate_datasets(\n",
    "\t\t\tdata, rstate=r, \n",
    "\t\t\tfeatures=features, target=target,\n",
    "\t\t\tinitial=initial, lowlevel=lowlevel,\n",
    "\t\t\ttrain_size=train_size)\n",
    "\t\tfor i, (model, parameter_range) in enumerate(zip(models, parameter_ranges)):\n",
    "\t\t\tprint(f\"Model: {model_names[i]}\")\n",
    "\t\t\tt0 = time.time()\n",
    "\t\t\t(train_error, test_error,\n",
    "\t\t\ttrain_r, test_r,\n",
    "\t\t\ttrain_sr, test_sr, \n",
    "\t\t\ttrain_kr, test_kr,) = evaluate_model(\n",
    "\t\t\t\tmodel, parameter_range, \n",
    "\t\t\t\tXtrain, Ytrain, Xtest, Ytest, \n",
    "\t\t\t\tplot=plot)\n",
    "\t\t\tt1 = time.time()\n",
    "\t\t\tprint(f\"Time taken: {round(t1-t0,3)}\\n\")\n",
    "\t\t\ttrain_scores[i] += train_error\n",
    "\t\t\ttest_scores[i] += test_error\n",
    "\t\t\ttrain_square_errors[i] += train_error**2\n",
    "\t\t\ttest_square_errors[i] += test_error**2\n",
    "\t\t\ttrain_pearsonr[i] += train_r\n",
    "\t\t\ttest_pearsonr[i] += test_r\n",
    "\t\t\ttrain_spearmanr[i] += train_sr\n",
    "\t\t\ttest_spearmanr[i] += test_sr\n",
    "\t\t\ttrain_kendalltau[i] += train_kr\n",
    "\t\t\ttest_kendalltau[i] += test_kr\n",
    "\tavg_train_mae = train_scores / n_repeats\n",
    "\tavg_test_mae = test_scores / n_repeats\n",
    "\tavg_train_maes = train_square_errors / n_repeats\n",
    "\tavg_test_maes = test_square_errors / n_repeats\n",
    "\tavg_train_sd = np.sqrt(np.abs(avg_train_maes - avg_train_mae**2))\n",
    "\tavg_test_sd = np.sqrt(np.abs(avg_test_maes - avg_test_mae**2))\n",
    "\tavg_train_pearsonr = train_pearsonr / n_repeats\n",
    "\tavg_test_pearsonr = test_pearsonr / n_repeats\n",
    "\tavg_train_spearmanr = train_spearmanr / n_repeats\n",
    "\tavg_test_spearmanr = test_spearmanr / n_repeats\n",
    "\tavg_train_kendalltau = train_kendalltau / n_repeats\n",
    "\tavg_test_kendalltau = test_kendalltau / n_repeats\n",
    "\toutput = (\n",
    "\t\tavg_train_mae,\n",
    "\t\tavg_test_mae,\n",
    "\t\tavg_train_sd,\n",
    "\t\tavg_test_sd,\n",
    "\t\tavg_train_pearsonr,\n",
    "\t\tavg_test_pearsonr,\n",
    "\t\tavg_train_spearmanr,\n",
    "\t\tavg_test_spearmanr,\n",
    "\t\tavg_train_kendalltau,\n",
    "\t\tavg_test_kendalltau,\n",
    "\t)\n",
    "\treturn output\n",
    "\n",
    "# Model constants\n",
    "models = [\n",
    "\tLinearRegression(),\n",
    "\tRidge(random_state=rng),\n",
    "    BayesianRidge(),\n",
    "    LinearSVR(random_state=rng),\n",
    "\tSVR(),\n",
    "\tRandomForestRegressor(random_state=rng),\n",
    "\tKernelRidge(),\n",
    "\tGaussianProcessRegressor(random_state=rng),\n",
    "\tXGBRegressor(random_state=rng)\n",
    "]\n",
    "model_names = [\n",
    "    \"LR\",\"RR\",\"BRR\",\"lSVR\",\"SVR\",\"RFR\",\"KRR\",\"GPR\",\"XGB\"\n",
    "]\n",
    "RBF_kernel = RBF()\n",
    "RQ_kernel = RationalQuadratic()\n",
    "Matern_kernel = Matern()\n",
    "ESS_kernel = ExpSineSquared()\n",
    "White_kernel = WhiteKernel()\n",
    "parameter_ranges = [\n",
    "    {\"fit_intercept\": [True, False]},\n",
    "    {\"alpha\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100]},\n",
    "    {\"alpha_1\":[1e-6],\n",
    "     \"alpha_2\":[1e-6],\n",
    "     \"lambda_1\":[1e-6],\n",
    "     \"lambda_2\":[1e-6]\n",
    "    },\n",
    "    {\"C\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100]},\n",
    "\t{\"C\": [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10,100],\n",
    "  \t\"kernel\": [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
    "\t\"degree\": [1,2,3],\n",
    "\t\"epsilon\": [1.0,0.1,0.001,0.0001],\n",
    "\t},\n",
    "    {\"n_estimators\": [50, 100, 200],\n",
    "     \"max_depth\": [5, 10, 50, 100]\n",
    "    },\n",
    "    {\"kernel\": [\"poly\"],\n",
    "     \"alpha\": [1e-3,1e-2,1e-1,1],\n",
    "     \"gamma\": [1e-3,1e-2,1e-1,1],\n",
    "     \"degree\": [2, 3, 4]\n",
    "    },\n",
    "    {\"kernel\": [\n",
    "\t\t1.0 * RBF_kernel,\n",
    "    \t1.0 * RQ_kernel,\n",
    "    \t1.0 * Matern_kernel,\n",
    "\t\t1.0 * RQ_kernel + 1.0 * Matern_kernel,\n",
    "    \t],\n",
    "    },\n",
    "    {\"n_estimators\": [50, 100, 200],\n",
    "     \"max_depth\": [5, 10, 50, 100],\n",
    "     \"eta\": [0.1, 0.01, 0.001],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d753281",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate data on different combinations of features and models\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttargets = [\n",
    "\t\t\"EGFR\",\"JAK2\",\"LCK\",\"MAOB\",\"NOS1\",\"PARP1\",\"ACHE\",\n",
    "\t\t\"PDE5A\",\"PTGS2\",\"ESR1\",\"AR\",\"NR3C1\",\"F10\",\"ADRB2\"]\n",
    "\tfor target in targets:\n",
    "\t\tprint()\n",
    "\t\tprint(target)\n",
    "\t\tdataset = f\"{target}-2048_data_3d_delta_pKi.csv\"\n",
    "\t\tdata = pd.read_csv(os.path.join(\"data\",dataset))\n",
    "\t\tlowlevel = \"XGB\"\n",
    "\t\ttrain_size = 10\n",
    "\t\tlist_initials = [\n",
    "\t\t\t\"random\",\n",
    "\t\t\t\"cpca\",\n",
    "\t\t\t\"top\"\n",
    "\t\t]\n",
    "\t\tlist_features = [\n",
    "\t\t\t[\"morgan3\"],\n",
    "\t\t\t[\"morgan3\",\"rdkit2d\"],\n",
    "\t\t\t[\"morgan3\",\"docking\"],\n",
    "\t\t\t[\"morgan3\",\"rdkit2d\",\"docking\"],\n",
    "\t\t\t[\"morgan3\",\"rdkit3d\",\"delta\",\"docking\"],\n",
    "\t\t\t[\"morgan3\",\"rdkit2d\",\"rdkit3d\",\"delta\",\"docking\"],\n",
    "\t\t]\n",
    "\t\tfor initial, features in itertools.product(list_initials,list_features):\n",
    "\t\t\t(\n",
    "\t\t\tavg_train_mae, \n",
    "\t\t\tavg_test_mae, \n",
    "\t\t\tavg_train_sd,\n",
    "\t\t\tavg_test_sd,\n",
    "\t\t\tavg_train_pearsonr,\n",
    "\t\t\tavg_test_pearsonr,\n",
    "\t\t\tavg_train_spearmanr,\n",
    "\t\t\tavg_test_spearmanr,\n",
    "\t\t\tavg_train_kendalltau,\n",
    "\t\t\tavg_test_kendalltau,\n",
    "\t\t\t) = test_models(\n",
    "\t\t\t\tmodels, parameter_ranges, data, \n",
    "\t\t\t\tfeatures=features,\n",
    "\t\t\t\tinitial=initial, lowlevel=lowlevel,\n",
    "\t\t\t\ttrain_size=train_size, plot=False)\n",
    "\t\t\tdictionary = {\n",
    "\t\t\t\t\"Model\": model_names, \n",
    "\t\t\t\t\"Train MAE (log M)\": np.round(avg_train_mae,3), \n",
    "\t\t\t\t\"Test MAE (log M)\": np.round(avg_test_mae,3), \n",
    "\t\t\t\t\"Train STD (log M)\": np.round(avg_train_sd,3),\n",
    "\t\t\t\t\"Test STD (log M)\": np.round(avg_test_sd,3),\n",
    "\t\t\t\t\"Train Pearson's R\": np.round(avg_train_pearsonr,3),\n",
    "\t\t\t\t\"Test Pearson's R\": np.round(avg_test_pearsonr,3),\n",
    "\t\t\t\t\"Train Spearman's R\": np.round(avg_train_spearmanr,3),\n",
    "\t\t\t\t\"Test Spearman's R\": np.round(avg_test_spearmanr,3),\n",
    "\t\t\t\t\"Train Kendall's Tau\": np.round(avg_train_kendalltau,3),\n",
    "\t\t\t\t\"Test Kendall's Tau\": np.round(avg_test_kendalltau,3),\n",
    "\t\t\t}\n",
    "\t\t\tdataframe = pd.DataFrame(dictionary)\n",
    "\t\t\tdisplay(dataframe)\n",
    "\t\t\tinit = \"_\"+initial\n",
    "\t\t\tif initial == \"top\": init += \"_\"+lowlevel+\"_P90\"\n",
    "\t\t\telif initial == \"random\": init = \"\"\n",
    "\t\t\tsavefile = dataset.split(\"_\")[0]+\"_\"+\"_\".join(features)+\"_\"+str(train_size)+init+\".csv\"\n",
    "\t\t\tsavedir = os.path.join(target,\"supervised_learning\")\n",
    "\t\t\tif not os.path.exists(savedir): os.makedirs(savedir)\n",
    "\t\t\tdataframe.to_csv(os.path.join(savedir,savefile),index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
